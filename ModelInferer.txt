#ifndef ANALYSIS_MODELINFERER_H
#define ANALYSIS_MODELINFERER_H

#include <vector>
#include <string>
#include <memory> // For std::shared_ptr
#include <algorithm>
#include <cmath>
#include <stdexcept> // For std::runtime_error

#include <torch/script.h>
#include <torch/torch.h> 

namespace analysis {

class ModelInferer {
public:
    ModelInferer(const std::string& encoder_path,
                 const std::string& classifier_path,
                 int model_img_height,
                 int model_img_width,
                 int model_classifier_input_channels,
                 int model_classifier_map_h,
                 int model_classifier_map_w,
                 bool use_gpu_if_available)
        : fDevice(init_device(use_gpu_if_available)),
          fModelImgHeight(model_img_height),
          fModelImgWidth(model_img_width),
          fModelClassifierInputChannels(model_classifier_input_channels),
          fModelClassifierMapH(model_classifier_map_h),
          fModelClassifierMapW(model_classifier_map_w),
          fModelsLoadedSuccessfully(false)
    {
        try {
            fEncoderModule = torch::jit::load(encoder_path, fDevice); 
            fClassifierModule = torch::jit::load(classifier_path, fDevice);

            if (!fEncoderModule) {
                 throw std::runtime_error("ModelInferer: Encoder model failed to load (returned null). Path: " + encoder_path);
            }
            if (!fClassifierModule) {
                 throw std::runtime_error("ModelInferer: Classifier model failed to load (returned null). Path: " + classifier_path);
            }

            fEncoderModule->eval(); // Try this instead of eval() for older LibTorch
            fClassifierModule->eval(); // Try this instead of eval()
            fModelsLoadedSuccessfully = true;
        } catch (const c10::Error& e) {
            fModelsLoadedSuccessfully = false;
            throw std::runtime_error("ModelInferer: c10::Error during model load/setup: " + std::string(e.what()));
        } catch (const std::runtime_error& e) { 
            fModelsLoadedSuccessfully = false;
            throw; 
        }
    }

    template<typename T>
    torch::Tensor preprocess_single_view(const std::vector<T>& view_data,
                                         int input_img_height, int input_img_width,
                                         int target_model_height, int target_model_width) {
        long current_total_pixels = static_cast<long>(input_img_height) * input_img_width;
        if (static_cast<long>(view_data.size()) != current_total_pixels && !view_data.empty()) {
            // Mismatch handling or logging
        }

        long target_len = static_cast<long>(target_model_height) * target_model_width;
        std::vector<float> processed_plane_vec(target_len, 0.0f); 
        long current_len = view_data.size();

        if (target_len == 0 && current_len == 0) {
            return torch::empty({0}, torch::kFloat32).reshape({1, 1, 0, 0}).to(fDevice);
        }
        if (target_len > 0 && current_len == 0) {
            // processed_plane_vec is already zeros
        } else if (target_len == 0 && current_len > 0) {
            return torch::empty({0}, torch::kFloat32).reshape({1, 1, 0, 0}).to(fDevice);
        } else if (target_len > 0) { 
            size_t len_to_copy = std::min(static_cast<size_t>(current_len), static_cast<size_t>(target_len));
            std::transform(view_data.begin(), view_data.begin() + len_to_copy, processed_plane_vec.begin(),
                           [](T val){ return static_cast<float>(val); });
        } else { 
             return torch::empty({0}, torch::kFloat32).reshape({1, 1, 0, 0}).to(fDevice);
        }

        if (target_len > 0 && !processed_plane_vec.empty()) {
            float min_val_img = 0.0f;
            float max_val_img = 0.0f;
            if (!processed_plane_vec.empty()) { 
                 min_val_img = *std::min_element(processed_plane_vec.begin(), processed_plane_vec.end());
                 max_val_img = *std::max_element(processed_plane_vec.begin(), processed_plane_vec.end());
            }

            if (max_val_img > min_val_img) {
                for (long i = 0; i < target_len; ++i) {
                    processed_plane_vec[i] = (processed_plane_vec[i] - min_val_img) / (max_val_img - min_val_img);
                }
            } else if (max_val_img == min_val_img && min_val_img != 0.0f) {
                std::fill(processed_plane_vec.begin(), processed_plane_vec.end(), 1.0f);
            } else { 
                std::fill(processed_plane_vec.begin(), processed_plane_vec.end(), 0.0f);
            }
        }
        
        return torch::from_blob(processed_plane_vec.data(), {1, target_model_height, target_model_width}, torch::kFloat32).clone().to(fDevice);
    }

    template<typename T_RAW, typename T_RECO>
    float get_score_for_plane(const std::vector<T_RAW>& raw_view_data,
                              const std::vector<T_RECO>& reco_view_data,
                              int current_img_height, int current_img_width) {
        if (!fModelsLoadedSuccessfully) {
            return -1.0f; 
        }

        torch::NoGradGuard no_grad;

        torch::Tensor raw_tensor = preprocess_single_view(raw_view_data, current_img_height, current_img_width, fModelImgHeight, fModelImgWidth);
        torch::Tensor reco_tensor = preprocess_single_view(reco_view_data, current_img_height, current_img_width, fModelImgHeight, fModelImgWidth);

        if (raw_tensor.numel() == 0 || reco_tensor.numel() == 0) {
            return -2.0f; 
        }

        torch::Tensor encoder_input = torch::cat({raw_tensor, reco_tensor}, 0).unsqueeze(0).to(fDevice);
        torch::Tensor embedding;
        try {
            embedding = fEncoderModule->forward({encoder_input}).toTensor(); 
        } catch (const c10::Error& e) {
            return -3.0f; 
        }

        long expected_embedding_elements = static_cast<long>(fModelClassifierInputChannels) * fModelClassifierMapH * fModelClassifierMapW;
        if (embedding.numel() != expected_embedding_elements) {
            return -4.0f; 
        }
        torch::Tensor classifier_input = embedding.reshape({1, fModelClassifierInputChannels, fModelClassifierMapH, fModelClassifierMapW});
        
        torch::Tensor logit;
        try {
            logit = fClassifierModule->forward({classifier_input}).toTensor(); 
        } catch (const c10::Error& e) {
            return -5.0f; 
        }

        float score = 1.0f / (1.0f + std::exp(-logit.item<float>()));
        return score;
    }

    bool models_loaded_successfully() const {
        return fModelsLoadedSuccessfully;
    }
    
    std::string get_device_name() const {
        if (fDevice.is_cuda()) return "CUDA";
        return "CPU";
    }

private:
    static torch::Device init_device(bool use_gpu_if_available) {
        if (use_gpu_if_available && torch::cuda::is_available()) {
            return torch::Device(torch::kCUDA);
        }
        return torch::Device(torch::kCPU);
    }

    torch::Device fDevice; 
    std::shared_ptr<torch::jit::script::Module> fEncoderModule; 
    std::shared_ptr<torch::jit::script::Module> fClassifierModule; 
    int fModelImgHeight;
    int fModelImgWidth;
    int fModelClassifierInputChannels;
    int fModelClassifierMapH;
    int fModelClassifierMapW;
    bool fModelsLoadedSuccessfully;
};

} 
#endif